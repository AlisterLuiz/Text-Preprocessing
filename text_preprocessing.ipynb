{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "This notebook showcases various functions which cleans up text data and prepares it for Model Training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be going through the following Text Cleaning Pipeline:\n",
    "\n",
    "- Text to Lowercase\n",
    "- Clean HTML Texts\n",
    "- Remove URLs\n",
    "- Split on Numbers\n",
    "- Expand Contractions\n",
    "- Remove Punctuation\n",
    "- Remove Stopwords\n",
    "- Remove Numbers\n",
    "- Shrink Extra Spaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Libraries Used:__\n",
    "\n",
    "1. [Pandas](https://pandas.pydata.org/)\n",
    "2. [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/#)\n",
    "3. [String](https://docs.python.org/3/library/string.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's get started!__\n",
    "\n",
    "First let's install the libraries and import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pandas\n",
    "%pip install -q beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Hey Amazon - my package never arrived but it shows it's delivered https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first PLEASE FIX IT! \\n <html> Amazon2022 © <br/> <br /> </html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([text], columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey amazon - my package never arrived but it shows it's delivered https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first please fix it! \\n <html> amazon2022 © <br/> <br /> </html>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean HTML Text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/#) is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning HTML Characters\n",
    "df[\"text\"] = df[\"text\"].apply(\n",
    "    lambda x: BeautifulSoup(x, \"html.parser\").text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey amazon - my package never arrived but it shows it's delivered https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first please fix it! \\n  amazon2022 ©   \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are patterns used to match character combinations in strings.\n",
    "\n",
    "[Reference](https://en.wikipedia.org/wiki/Regular_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Remove URLs\n",
    "df[\"text\"] = df[\"text\"].str.replace(\n",
    "    r\"https?:\\/\\/.\\S+\", \"\", regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon package never arrived shows delivered please fix amazon'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Numbers from Words\n",
    "df[\"text\"] = df[\"text\"].str.split(\n",
    "    r\"(\\d+)\", regex=True\n",
    ")\n",
    "df[\"text\"] = df[\"text\"].apply(\n",
    "    \" \".join\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey amazon - my package never arrived but it shows it's delivered  please fix it! \\n  amazon 2022  ©   \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Contracted Words\n",
    "contractions = {\n",
    "        \"'s\": \" is\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'m\": \" am\",\n",
    "        \"'ll\": \" will\",\n",
    "        \"'d\": \" would\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"'re\": \" are\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in contractions.items():\n",
    "    df[\"text\"] = df[\"text\"].str.replace(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon - my package never arrived but it shows it is delivered  please fix it! \\n  amazon 2022  ©   '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Punctuation List\n",
    "extra_punct = [\n",
    "        \",\", \".\", '\"', \":\", \")\", \"(\", \"!\", \"?\", \"|\", \";\", \"'\", \"&\", \n",
    "        \"/\", \"[\", \"]\", \">\", \"%\", \"=\", \"#\", \"*\", \"+\", \"\\\\\", \"•\", \"~\", \n",
    "        \"@\", \"·\", \"_\", \"{\", \"}\", \"©\", \"^\", \"®\", \"`\", \"<\", \"→\", \"°\", \n",
    "        \"€\", \"™\", \"›\", \"♥\", \"←\", \"×\", \"§\", \"″\", \"′\", \"Â\", \"█\", \"½\", \n",
    "        \"à\", \"…\", \"“\", \"★\", \"”\", \"–\", \"●\", \"â\", \"►\", \"−\", \"¢\", \"²\", \n",
    "        \"¬\", \"░\", \"¶\", \"↑\", \"±\", \"¿\", \"▾\", \"═\", \"¦\", \"║\", \"―\", \"¥\", \n",
    "        \"▓\", \"—\", \"‹\", \"─\", \"▒\", \"：\", \"¼\", \"⊕\", \"▼\", \"▪\", \"†\", \"■\", \n",
    "        \"’\", \"▀\", \"¨\", \"▄\", \"♫\", \"☆\", \"é\", \"¯\", \"♦\", \"¤\", \"▲\", \"è\", \n",
    "        \"¸\", \"¾\", \"Ã\", \"⋅\", \"‘\", \"∞\", \"∙\", \"）\", \"↓\", \"、\", \"│\", \"（\", \n",
    "        \"»\", \"，\", \"♪\", \"╩\", \"╚\", \"³\", \"・\", \"╦\", \"╣\", \"╔\", \"╗\", \"▬\", \n",
    "        \"❤\", \"ï\", \"Ø\", \"¹\", \"≤\", \"‡\", \"√\", \"«\", \"»\", \"´\", \"º\", \"¾\", \n",
    "        \"¡\", \"§\",\n",
    "        ]\n",
    "\n",
    "punctuation = list(string.punctuation) + extra_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1500\\4054425180.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df[\"text\"] = df[\"text\"].str.replace(punct, \"\")\n"
     ]
    }
   ],
   "source": [
    "for punct in list(punctuation):\n",
    "    df[\"text\"] = df[\"text\"].str.replace(punct, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon  my package never arrived but it shows it is delivered  please fix it \\n  amazon 2022     '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Stopwords Removal\n",
    "stopwords = [\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"you're\", \n",
    "    \"you've\", \"you'll\", \"you'd\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \n",
    "    \"him\", \"his\", \"himself\", \"she\", \"she's\", \"her\", \"hers\", \"herself\", \"it\", \"it's\", \n",
    "    \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n",
    "    \"who\", \"whom\", \"this\", \"that\", \"that'll\", \"these\", \"those\", \"am\", \"is\", \"are\", \n",
    "    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n",
    "    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n",
    "    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \n",
    "    \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \n",
    "    \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \n",
    "    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \n",
    "    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"can\", \"will\", \"just\", \"don\", \n",
    "    \"don't\", \"should\", \"should've\", \"now\", \"ll\", \"re\", \"ve\", \"ain\", \"aren\", \"aren't\", \"couldn\", \"couldn't\", \n",
    "    \"didn\", \"didn't\", \"doesn\", \"doesn't\", \"hadn\", \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\", \"isn\", \n",
    "    \"isn't\", \"ma\", \"mightn\", \"mightn't\", \"mustn\", \"mustn't\", \"needn\", \"needn't\", \"shan\", \"shan't\", \"shouldn\", \n",
    "    \"shouldn't\", \"wasn\", \"wasn't\", \"weren\", \"weren't\", \"won\", \"won't\", \"wouldn\", \"wouldn't\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative method,\n",
    "\n",
    "```\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "df['text'] = df['text'].str.replace(pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon   package never arrived   shows   delivered  please fix  \\n  amazon 2022     '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Numbers\n",
    "df['text'] = df['text'].str.replace(r'\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon   package never arrived   shows   delivered  please fix  \\n  amazon      '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrink Extra Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink Extra Spaces\n",
    "df[\"text\"] = df[\"text\"].str.strip().replace(r\"\\s+\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon package never arrived shows delivered please fix amazon'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have completed the text preprocessing pipeline, let's compare the starting text with the final preprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Amazon - my package never arrived but it shows it's delivered https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first PLEASE FIX IT! \n",
      " <html> Amazon2022 © <br/> <br /> </html>\n",
      "\n",
      "\n",
      "hey amazon package never arrived shows delivered please fix amazon\n"
     ]
    }
   ],
   "source": [
    "print(f\"{text}\\n\\n\\n{df.iat[0,0]}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Preprocessing the DataFrame containing Text Data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    df[\"text\"] = df[\"text\"].str.lower()\n",
    "    # Cleaning HTML Characters\n",
    "    df[\"text\"] = df[\"text\"].apply(\n",
    "        lambda x: BeautifulSoup(x, \"html.parser\").text\n",
    "    )\n",
    "    # Remove URLs\n",
    "    df[\"text\"] = df[\"text\"].str.replace(\n",
    "        r\"https?:\\/\\/.\\S+\", \"\", regex=True\n",
    "    )\n",
    "    # Split Numbers from Words\n",
    "    df[\"text\"] = df[\"text\"].str.split(r\"(\\d+)\")\n",
    "    df[\"text\"] = df[\"text\"].apply(\" \".join)\n",
    "    # Remove Contracted Words\n",
    "    contractions = {\n",
    "        \"'s\": \" is\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'m\": \" am\",\n",
    "        \"'ll\": \" will\",\n",
    "        \"'d\": \" would\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"'re\": \" are\",\n",
    "    }\n",
    "    for key, value in contractions.items():\n",
    "        df[\"text\"] = df[\"text\"].str.replace(key, value)\n",
    "    # Extra Punctuation List\n",
    "    extra_punct = [\n",
    "        \",\", \".\", '\"', \":\", \")\", \"(\", \"!\", \"?\", \"|\", \";\", \"'\", \"&\", \n",
    "        \"/\", \"[\", \"]\", \">\", \"%\", \"=\", \"#\", \"*\", \"+\", \"\\\\\", \"•\", \"~\", \n",
    "        \"@\", \"·\", \"_\", \"{\", \"}\", \"©\", \"^\", \"®\", \"`\", \"<\", \"→\", \"°\", \n",
    "        \"€\", \"™\", \"›\", \"♥\", \"←\", \"×\", \"§\", \"″\", \"′\", \"Â\", \"█\", \"½\", \n",
    "        \"à\", \"…\", \"“\", \"★\", \"”\", \"–\", \"●\", \"â\", \"►\", \"−\", \"¢\", \"²\", \n",
    "        \"¬\", \"░\", \"¶\", \"↑\", \"±\", \"¿\", \"▾\", \"═\", \"¦\", \"║\", \"―\", \"¥\", \n",
    "        \"▓\", \"—\", \"‹\", \"─\", \"▒\", \"：\", \"¼\", \"⊕\", \"▼\", \"▪\", \"†\", \"■\", \n",
    "        \"’\", \"▀\", \"¨\", \"▄\", \"♫\", \"☆\", \"é\", \"¯\", \"♦\", \"¤\", \"▲\", \"è\", \n",
    "        \"¸\", \"¾\", \"Ã\", \"⋅\", \"‘\", \"∞\", \"∙\", \"）\", \"↓\", \"、\", \"│\", \"（\", \n",
    "        \"»\", \"，\", \"♪\", \"╩\", \"╚\", \"³\", \"・\", \"╦\", \"╣\", \"╔\", \"╗\", \"▬\", \n",
    "        \"❤\", \"ï\", \"Ø\", \"¹\", \"≤\", \"‡\", \"√\", \"«\", \"»\", \"´\", \"º\", \"¾\", \n",
    "        \"¡\", \"§\",\n",
    "    ]\n",
    "    punctuation = list(string.punctuation) + extra_punct\n",
    "    for punct in list(punctuation):\n",
    "        df[\"text\"] = df[\"text\"].str.replace(punct, \"\", regex=False)\n",
    "    # Stopwords Removal\n",
    "    stopwords = [\n",
    "        \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"you're\", \n",
    "        \"you've\", \"you'll\", \"you'd\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \n",
    "        \"him\", \"his\", \"himself\", \"she\", \"she's\", \"her\", \"hers\", \"herself\", \"it\", \"it's\", \n",
    "        \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n",
    "        \"who\", \"whom\", \"this\", \"that\", \"that'll\", \"these\", \"those\", \"am\", \"is\", \"are\", \n",
    "        \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n",
    "        \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n",
    "        \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \n",
    "        \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \n",
    "        \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \n",
    "        \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \n",
    "        \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"can\", \"will\", \"just\", \"don\", \n",
    "        \"don't\", \"should\", \"should've\", \"now\", \"ll\", \"re\", \"ve\", \"ain\", \"aren\", \"aren't\", \"couldn\", \"couldn't\", \n",
    "        \"didn\", \"didn't\", \"doesn\", \"doesn't\", \"hadn\", \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\", \"isn\", \n",
    "        \"isn't\", \"ma\", \"mightn\", \"mightn't\", \"mustn\", \"mustn't\", \"needn\", \"needn't\", \"shan\", \"shan't\", \"shouldn\", \n",
    "        \"shouldn't\", \"wasn\", \"wasn't\", \"weren\", \"weren't\", \"won\", \"won't\", \"wouldn\", \"wouldn't\",\n",
    "    ]\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "    df['text'] = df['text'].str.replace(pattern, '', regex=True)\n",
    "    # Remove Numbers\n",
    "    df['text'] = df['text'].str.replace(r'\\d+', '', regex=True)\n",
    "    # Shrink Extra Spaces\n",
    "    df[\"text\"] = df[\"text\"].str.strip().replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([text], columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey Amazon - my package never arrived but it shows it's delivered https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first PLEASE FIX IT! \\n <html> Amazon2022 © <br/> <br /> </html>\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon package never arrived shows delivered please fix amazon'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessing(df).iat[0, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
